"""
Brain state management for neuromorphic computing.

Implements a neuromodulatory state manager that simulates
aspects of brain chemistry during learning processes.
"""

import enum
import time
from enum import Enum, auto
from typing import Any, Dict, Iterator, List, Optional, Tuple, Union

import torch
from torch.nn.parameter import Parameter


class ModulationType(enum.Enum):
    """Types of neuromodulation in the brain system."""

    ATTENTION = "attention"
    PLASTICITY = "plasticity"
    ENERGY = "energy"


class NeurotransmitterType(enum.Enum):
    """Types of neurotransmitters simulated in the system."""

    DOPAMINE = "dopamine"  # Reward and motivation
    NOREPINEPHRINE = "norepinephrine"  # Arousal and alertness


class NeuromodulationType(Enum):
    """Enumeration of neuromodulatory effects in the brain"""

    DOPAMINE = auto()  # Reward signal, reinforcement
    NOREPINEPHRINE = auto()  # Arousal, alertness
    SEROTONIN = auto()  # Mood regulation, confidence
    ACETYLCHOLINE = auto()  # Attention, focus


class BrainState:
    """
    Class representing the neuromodulatory state for brain-inspired learning.

    This tracks the state of different neurotransmitters to modulate learning:
    - Dopamine-like signals for reward (engagement)
    - Norepinephrine-like signals for arousal
    """

    def __init__(
        self,
        engagement: float = 0.5,
        arousal: float = 0.5,
        adaptation_rate: float = 0.01,
        hebbian_strength: float = 0.2,
        last_update_time: Optional[float] = None,
        interaction_count: int = 0,
    ) -> None:
        """
        Initialize the brain state with default values.

        :param engagement: Initial engagement level (0-1)
        :param arousal: Initial arousal level (0-1)
        :param adaptation_rate: Rate of adaptation to new stimuli
        :param hebbian_strength: Strength of Hebbian learning
        :param last_update_time: Time of last update (defaults to current time)
        :param interaction_count: Count of interactions
        """
        self.engagement = engagement
        self.arousal = arousal
        self.adaptation_rate = adaptation_rate
        self.hebbian_strength = hebbian_strength
        self.last_update_time = (
            last_update_time if last_update_time is not None else time.time()
        )
        self.interaction_count = interaction_count

    def to_dict(self) -> Dict[str, Union[float, int]]:
        """
        Convert the brain state to a dictionary representation.

        :return: Dictionary containing brain state parameters
        """
        return {
            "engagement": self.engagement,
            "arousal": self.arousal,
            "adaptation_rate": self.adaptation_rate,
            "hebbian_strength": self.hebbian_strength,
            "last_update_time": self.last_update_time,
            "interaction_count": self.interaction_count,
        }

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> "BrainState":
        """
        Create a BrainState object from a dictionary.

        :param data: Dictionary containing brain state parameters
        :return: Initialized BrainState object
        """
        return cls(
            engagement=float(data.get("engagement", 0.5)),
            arousal=float(data.get("arousal", 0.5)),
            adaptation_rate=float(data.get("adaptation_rate", 0.01)),
            hebbian_strength=float(data.get("hebbian_strength", 0.2)),
            last_update_time=float(data.get("last_update_time", time.time())),
            interaction_count=int(data.get("interaction_count", 0)),
        )

    def update(self, user_input: str, response: Optional[str] = None) -> None:
        """
        Update the brain state based on user input and system response.

        This simulates changes in engagement and arousal from interaction.

        :param user_input: The input provided by the user
        :param response: The response generated by the system
        """
        # Calculate time-based decay (neurotransmitter clearance)
        current_time = time.time()
        time_delta = current_time - self.last_update_time
        decay_factor = 1.0 / (1.0 + time_delta * 0.1)

        # Apply decay to engagement and arousal
        self.engagement *= decay_factor
        self.arousal *= decay_factor

        # Process feedback from interaction
        feedback_engagement, feedback_arousal = self._process_feedback(
            user_input, response
        )

        # Update brain state using feedback and adaptation rate
        self.engagement += self.adaptation_rate * (
            feedback_engagement - self.engagement
        )
        self.arousal += self.adaptation_rate * (feedback_arousal - self.arousal)

        # Ensure values stay within valid ranges
        self.engagement = max(0.0, min(1.0, self.engagement))
        self.arousal = max(0.0, min(1.0, self.arousal))

        # Update timestamp and interaction count
        self.last_update_time = current_time
        self.interaction_count += 1

    def _process_feedback(
        self, user_input: str, response: Optional[str] = None
    ) -> Tuple[float, float]:
        """
        Analyze user input and response to determine engagement and arousal factors.

        This uses simple heuristics to estimate the emotional state from text.

        :param user_input: The input provided by the user
        :param response: The response generated by the system
        :return: Tuple of (engagement_factor, arousal_factor)
        """
        # Default values
        engagement_factor = 0.5
        arousal_factor = 0.5

        # Simple positive/negative sentiment analysis
        positive_words = ["good", "great", "like", "love", "thank", "thanks", "amazing"]
        negative_words = ["bad", "wrong", "terrible", "hate", "dislike", "error"]

        # Process user input
        user_input_lower = user_input.lower()

        # Count positive and negative sentiment markers
        pos_count = sum(word in user_input_lower for word in positive_words)
        neg_count = sum(word in user_input_lower for word in negative_words)

        # Determine engagement based on sentiment
        if pos_count > neg_count:
            engagement_factor = 0.7 + (
                pos_count * 0.05
            )  # Increase engagement for positive feedback
        elif neg_count > pos_count:
            engagement_factor = 0.3 - (
                neg_count * 0.05
            )  # Decrease engagement for negative feedback

        # Determine arousal based on input length and punctuation
        question_marks = user_input.count("?")
        exclamation_marks = user_input.count("!")
        arousal_factor = 0.5 + (question_marks * 0.05) + (exclamation_marks * 0.1)

        # Add arousal for longer inputs (more cognitive effort)
        if len(user_input) > 100:
            arousal_factor += 0.1

        # Cap factors to valid range
        engagement_factor = max(0.1, min(0.9, engagement_factor))
        arousal_factor = max(0.1, min(0.9, arousal_factor))

        return engagement_factor, arousal_factor

    def apply_to_parameters(
        self, parameters: Union[List[Parameter], Iterator[Tuple[str, Parameter]]]
    ) -> None:
        """
        Apply neurochemical modulation to model parameters.

        :param parameters: List of model parameters or iterator of (name, parameter) pairs to modulate
        """
        # Handle both parameter list and named parameter iterator
        param_list: List[Parameter] = []
        if isinstance(parameters, list):
            param_list = parameters
        else:
            # Extract parameters from named parameter iterator
            param_list = [param for _, param in parameters]

        # Apply engagement level (dopamine-like) to adjust learning sensitivity
        for param in param_list:
            if param.grad is not None:
                # Scale gradients by engagement level
                param.grad *= self.engagement

                # Apply arousal effects (norepinephrine-like)
                if self.arousal > 0.7:  # High arousal - increase exploration
                    noise_scale = (self.arousal - 0.7) * 0.1
                    noise = torch.randn_like(param.data) * noise_scale
                    param.grad += noise

    def modulate_gradients(
        self, named_parameters: Iterator[Tuple[str, Parameter]]
    ) -> None:
        """
        Modulate gradients based on neuromodulatory factors.

        This applies brain-inspired modulation to parameter gradients:
        - Engagement (dopamine-like) controls learning strength
        - Arousal (norepinephrine-like) controls exploration

        :param named_parameters: Iterator of (name, parameter) pairs
        """
        for name, param in named_parameters:
            if param.grad is None:
                continue

            # Apply engagement-based modulation (dopamine-like)
            param.grad *= self.engagement

            # Apply arousal-based modulation (norepinephrine-like)
            if self.arousal > 0.7:
                noise_scale = (self.arousal - 0.7) * 0.1
                param.grad += torch.randn_like(param.grad) * noise_scale

            # Layer-specific modulation based on name
            if "embedding" in name:
                # Conceptual foundation should be stable
                param.grad *= 0.8
            elif "output" in name:
                # Output layer should be more plastic
                param.grad *= 1.2

    def get_temperature(self, base_temp: float = 1.0) -> float:
        """
        Get temperature modulated by engagement level.

        Lower engagement results in higher temperature (more exploration).

        :param base_temp: Base temperature value
        :return: Modulated temperature
        """
        return base_temp * (1.0 + (1.0 - self.engagement) * 0.5)

    def get_temperature_modulation(self) -> float:
        """
        Get a temperature value modulated by engagement level.

        Low engagement -> higher temperature (more exploration)
        High engagement -> lower temperature (more exploitation)

        :return: Temperature value for sampling
        """
        # Base temperature
        base_temp = 0.8

        # Modulate by inverse of engagement
        # Low engagement (bored) -> higher temp -> more exploration
        # High engagement (focused) -> lower temp -> more exploitation
        modulation = 1.0 - self.engagement

        # Calculate final temperature, keeping within reasonable bounds
        temp = base_temp + (modulation * 0.5)
        return max(0.5, min(1.5, temp))
